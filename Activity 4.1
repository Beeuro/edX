-Jupyter Intro
import pandas as pd

# Define the data
data = {
    "cell_type": ["code", "code", "code", "code", "code", "code"],
    "execution_count": [1, 2, 3, 4, 5, 6],
    "outputs": [
        {"stdout": ["Hello World"]},
        {"execute_result": {"text/plain": ["8"]}},
        {},
        {"execute_result": {"text/plain": ["5"]}},
        {},
        {"execute_result": {"text/plain": ["2"]}},
    ],
    "source": [
        "# Running the basic \"Hello World\" code",
        "# Doing simple math",
        "# Storing results in variables",
        "# Using those variables elsewhere in the code",
        "# Variables will hold the value most recently run\n# This means that, if we run the code above, it will now print 2",
        "",
    ],
}

# Create DataFrame
df = pd.DataFrame(data)

# Display DataFrame
df

-Comics Remix 
Step 1
# Modules
import os
import csv

# Prompt user for title lookup
book = input("What title are you looking for? ")

# Set path for file
csvpath = os.path.join("Resources", "comic_books.csv")

# Set variable to check if we found the video
found = False

# Open the CSV
with open(csvpath, encoding="utf8") as :
    csvreader = csv.reader(csvfile, delimiter=",")

    # Loop through looking for the video
    for row in csvreader:
        if row[0] == book:
            print(row[0] + " was published by " + row[8] + " in " + row[9])

            # Set variable to confirm we have found the video
            found = True

# If the book is never found, alert the user
if found is False:
    print("Sorry about this, we don't seem to have what you are looking for!")

Step 2
Cell 1
# Modules
import os
import csv

# Prompt user for title lookup
book = input("What title are you looking for? ")

Cell 2
# Set path for file
csvpath = os.path.join("Resources", "comic_books.csv")
csvpath

Cell 3
# Set variable to check if we found the video
found = False

# Open the CSV
with open(csvpath, encoding="utf8") as csvfile:
    csvreader = csv.reader(csvfile, delimiter=",")

    # Loop through looking for the video
    for row in csvreader:
        if row[0] == book:
            row[0] + " was published by " + row[8] + " in " + row[9]

            # Set variable to confirm we have found the video
            found = True

# If the book is never found, alert the user
if found is False:
    "Sorry about this, we don't seem to have what you are looking for!"

*[Bonus]

-Create Data Frame
import pandas as pd

# Cell 2
series_data = {
    "output_type": "execute_result",
    "data": {"text/plain": ["0                             UCLA\n1                      UC Berkeley\n2                        UC Irvine\n3    University of Central Florida\n4               Rutgers University\ndtype: object"]},
}

# Create a Pandas Series from raw list
series_df = pd.Series(series_data["data"]["text/plain"])

# Cell 3
data_states = {
    "STATE": ["New Jersey", "New York"],
    "ABBREVIATION": ["NJ", "NY"],
}

# Convert a list of dictionaries into a DataFrame
df_states = pd.DataFrame(data_states)

# Cell 4
data_pharaohs = {
    "Dynasty": ["Early Dynastic Period", "Old Kingdom"],
    "Pharaoh": ["Thinis", "Memphis"],
}

# Convert a single dictionary containing lists into a DataFrame
df_pharaohs = pd.DataFrame(data_pharaohs)

# Display DataFrames
series_df, df_states, df_pharaohs

-Frame Shop
# Create a DataFrame for the frame shop
frame_data = {
    "Frame": ["Ornate", "Classical", "Modern", "Wood", "Cardboard"],
    "Price": [15.0, 12.5, 10.0, 5.0, 1.0],
    "Sales": [100, 200, 150, 300, "N/A"]
}

# Create a DataFrame for the art gallery
gallery_data = [
    {"Painting": "Mona Lisa (Knockoff)", "Price": 25, "Popularity": "Very Popular"},
    {"Painting": "Van Gogh (Knockoff)", "Price": 20, "Popularity": "Popular"},
    {"Painting": "Starving Artist", "Price": 10, "Popularity": "Average"},
    {"Painting": "Toddler Drawing", "Price": 1, "Popularity": "Not Popular"}
]

gallery_df = pd.DataFrame(gallery_data)
gallery_df

frame_df = pd.DataFrame(frame_data)
frame_df

Bonus: I prefer creating a data frame for the art gallery rather than a frame shop.

-Car Purchases
# Print Statistical Analysis Summary
print("Statistical Analysis of Car Purchases:")
print(statistical_analysis.to_string())

# Print Data Cleaning Summary for Missing Values
print("\nData Cleaning Check for Missing Values:")
print(missing_values.to_string())

# Concluding Remarks
missing_values_total = missing_values.sum()
data_cleaning_result = "The dataset has no missing values and is clean." if missing_values_total == 0 else "The dataset has missing values that need to be addressed."

concluding_remarks = f"""
The dataset contains 1000 records of car purchases. The purchase amounts vary significantly, with a mean of approximately $9988.74 and a wide range from $15.3 to $19927.9. This variation in purchase amounts could reflect a wide range of car models and preferences among buyers. {data_cleaning_result}
"""

print("\nConcluding Remarks:")
print(concluding_remarks)

-Training Grounds
A. Analytical Overview of Numeric Columns:
   - Weight:
     - Count: 200
     - Mean: 180.82
     - Standard Deviation: 39.37
     - Min: 110
     - 25th Percentile: 151
     - Median: 180.5
     - 75th Percentile: 215
     - Max: 250
   - Membership (Days):
     - Count: 200
     - Mean: 101.91
     - Standard Deviation: 60.16
     - Min: 1
     - 25th Percentile: 51
     - Median: 105.5
     - 75th Percentile: 157.25
     - Max: 200

B. Names of Trainers:
   - Array: ['Bettyann Savory', 'Mariah Barberio', 'Gordon Perrine', 'Pa Dargan', 'Blanch Victoria', 'Aldo Byler', 'Williams Camire', 'Junie Ritenour', 'Barton Stecklein', 'Brittani Brin', 'Phyliss Houk', 'Calvin North', 'Coleman Dunmire', 'Harland Coolidge']

C. Number of Students Each Trainer Has:
   - Bettyann Savory: 20
   - Mariah Barberio: 15
   - Gordon Perrine: 14
   - Pa Dargan: 14
   - Blanch Victoria: 14
   - Aldo Byler: 17
   - Williams Camire: 11
   - Junie Ritenour: 14
   - Barton Stecklein: 13
   - Brittani Brin: 16
   - Phyliss Houk: 16
   - Calvin North: 7
   - Coleman Dunmire: 17
   - Harland Coolidge: 12

D. Average Weight of Students:
   - 180.82

E. Combined Weight of All Students:
   - 36,164

F. Converted "Membership (Days)" to Weeks and Added to DataFrame:
   - See the last table in the code output.

-Column Manipulation
# Import Dependencies
import pandas as pd

# A DataFrame of individuals' names, their trainers, their weight, and their days as gym members
training_df = pd.DataFrame({
    "Name": ["Gino Walker", "Hiedi Wasser", "Kerrie Wetzel", "Elizabeth Sackett", "Jack Mitten", 
             "Madalene Wayman", "Jamee Horvath", "Arlena Reddin", "Tula Levan", "Teisha Dreier"],
    "Trainer": ['Bettyann Savory', 'Mariah Barberio', 'Gordon Perrine', 'Pa Dargan', 'Blanch Victoria', 
                'Aldo Byler', 'Aldo Byler', 'Williams Camire', 'Junie Ritenour', 'Gordon Perrine'],
    "Weight": [128, 180, 193, 177, 237, 166, 224, 208, 177, 241],
    "Membership(Days)": [52, 70, 148, 124, 186, 157, 127, 155, 37, 185]
})

# Collect a list of all columns within the DataFrame
training_df.columns

# Reorganize the columns using double brackets
training_df = training_df[['Name', 'Trainer', 'Weight', 'Membership(Days)']]

# Use .rename(columns={}) to rename columns
training_df = training_df.rename(columns={'Weight': 'Weight in Pounds', 'Membership(Days)': 'Membership in Days'})

training_df.head(5)

-Hey Arnold
# Rename columns for readability
hey_arnold_df = hey_arnold_df.rename(columns={
    "Character_in_show": "Character",
    "color_of_hair": "Hair Color",
    "Height": "Height",
    "Football_Shaped_Head": "Football Head"
})

# Organize the columns in the desired order
hey_arnold_df = hey_arnold_df[["Character", "Football Head", "Hair Color", "Height"]]

hey_arnold_df

-Website Data
Domain Frequency and Gender Breakdown scripted
# Gender Distribution Pie Chart
plt.figure(figsize=(8, 6))
plt.pie(gender_distribution, labels=gender_distribution.index, autopct='%1.1f%%', startangle=140)
plt.title('Gender Distribution')
plt.show()

# Top Email Domains Bar Chart
plt.figure(figsize=(10, 8))
email_domain_frequency.plot(kind='bar')
plt.title('Top Email Domains Frequency')
plt.xlabel('Email Domains')
plt.ylabel('Frequency')
plt.xticks(rotation=45)
plt.show()
# Load the Jupyter notebook to inspect its contents
import nbformat

Advanced Analysis: Extracting and analyzing first names
df['first_name'] = df['full_name'].apply(lambda x: x.split()[0])
first_name_frequency = df['first_name'].value_counts().head(10)  # top 10 most common first names

Exporting Processed Data
processed_file_path = '/mnt/data/Processed_DataOne.csv'
df.to_csv(processed_file_path, index=False, encoding='utf-8')

first_name_frequency, processed_file_path

-Comic Books
Data Cleaned
# Define the path for the new CSV file
new_csv_path = '/mnt/data/cleaned_comic_books.csv'

# Write the DataFrame to a new CSV file
df_cleaned.to_csv(new_csv_path, index=False)

# Return the path for confirmation
new_csv_path

-Comic Books Summary
Results Scripted
# Calculate the requested summary statistics

# Count of unique authors
unique_authors_count = df['Author'].nunique()

# Count of unique countries of publication
# Assuming countries are separated by ";"
countries = df['Country of Publication'].str.split(';').explode()
unique_countries_count = countries.nunique()

# Year of the earliest published book
earliest_year = df['Publication Year'].min()

# Year of the latest published book
latest_year = df['Publication Year'].max()

unique_authors_count, unique_countries_count, earliest_year, latest_year