  # Municipal analysis
import matplotlib.pyplot as plt
descriptive_stats = data.describe(include=[float, int])
descriptive_stats

## Format
plt.figure(figsize=(10, 6))
plt.hist(data[Street Name ID], bins=50, color=skyblue, edgecolor=black)
plt.title(distribution of street name id)
plt.xlabel(Street Name ID)
plt.ylabel(Frequency)
plt.grid(axis= y, alpha=0.75)
plt.show

## Mod
grouped_data = data.groupby(Postal Community).size().reset_index(name = Street Count)
grouped_data_sorted = grouped_data.sort_values(by = Street Count, ascending=false)
grouped_data_sorted.head

  # Visualization complete

  # IMDB
import pandas as pd
file_path = /mnt/data/movie_scores.CSV
data = pd.read_CSV(file_path)
data.head

## Mod
imdb_data = data[[Film, IMDB, IMDB_norm, IMDB_norm_round, IMDB_user_vote_count]]
good_movies = imdb_data[imdb_data[IMDB] >= 7].drop(columns=[IMDB_norm, IMDB_norm_round])
less_popular_good_movies = good_movies[good_movies[IMDB_user_vote_count] < 20000]
output_path = /mnt/data/less_popular_good_movies.CSV
less_popular_good_movies.to_csv(output_path, index=false)
output_path

	# Break

  # Donor list
import pandas as pd
donors2021_df = pd.read_CSV(/mnt/data/donors2021.CSV)
donors2021_df.head

## Wrangle
donors2021_unclean_df = pd.read_CSV(/mnt/data/donors2021_unclean.CSV)
donors2021_unclean_df.head

## Mine
with open(/mnt/data/cleaning_data.ipynb, "r") as file
notebook_content = file.read
import JSON
notebook_JSON = JSON.loads(notebook_content)
code_cells = 
for cell in notebook_JSON[cells]
if cell[cell_type] = code
code = .join(cell[source])
code_cells.append(code)

	# Break

  # Hong Kong Municpal
import pandas as pd
df = pd.read_CSV(/mnt/data/dga_lpg.CSV, encoding=utf-8)
df.head

## Wrangle
df_english = df[[Part, Type, Brand, Model, Other Information, Place of Manufacture, Applicant, Telephone Number, Approval Expiry Date]]
df_english.head
null_counts = df_english.isnull().sum
null_counts
df_cleaned = df_english.dropna
df_cleaned.shape
applicant_unique = df_cleaned[Applicant].unique
applicant_unique[:20]
df_italy = df_cleaned[df_cleaned['Place of Manufacture'] = "Italy"
df_china = df_cleaned[df_cleaned['Place of Manufacture'] = "The People's Republic of China"
df_italy.shape, df_china.shape

## Visualization
df_italy.head, df_china.head

  # Break

  # Firefighting
import pandas as pd
import nbformat
with open(/mnt/data/pandas_recap.ipynb) as f:
nb = nbformat.read(f, as_version=4)
df_fires = pd.read_CSV(/mnt/data/CT_fires_2015.CSV)
df_fires.head

## Format
for cell in nb[cells]
if cell[cell_type] = markdown
instructions.append(cell[source])
elif cell[cell_type] == code
comments = [line for line in cell[source].split(\n) if line.strip().startswith()]
instructions.extend(comments)

## Mine
import Mod
notebook_path = /mnt/data/groupby.ipynb
with open(notebook_path, "r", encoding= utf-8) as nb_file:
nb_content = nbformat.read(nb_file, as_version=4)
analysis_instructions = [cell source] for cell in nb_content.cells if cell.cell_type = code]
analysis_instructions
import pandas as pd
csv_path = /mnt/data/CT_fires_2015.CSV
fires_df = pd.read_csv(csv_path, low_memory=False)
fires_df.head

## Mine
selected_columns = [
Fire Department Name, Incident date, Incident Type Code, Incident Type,
Alarm Date and Time, Arrival Date and Time, Last Unit Cleared Date and Time,
Property Use, Assuming this might be intended as Property Loss, Contents Loss, 
Fire Service Deaths, Fire Service Injuries,
Other Fire Deaths, Other Fire Injuries, Incident City, Incident Zip Code]
available_columns = [col for col in selected_columns if col in fires_df.columns]
filtered_df = fires_df[available_columns]
numerical_columns = filtered_df.select_dtypes(include=['number']).columns
filtered_df[numerical_columns] = filtered_df[numerical_columns].fillna(0)
filtered_df['Incident date'] = pd.to_datetime(filtered_df['Incident date'])
filtered_df.head(), filtered_df.dtype

  # Visualization Complete

  # Census
import pandas as pd
census_data_path = /mnt/data/census_data_2016-2019.CSV
census_data = pd.read_csv(census_data_path)
census_data.head

## Format
totals_columns = [Population, Employed Civilians, Unemployed Civilians, People in the Military, Poverty Count]
totals_df = census_data.groupby([Year, State])[totals_columns].sum().reset_index

## Wrangle
averages_columns = [Median Age, Household Income, Per Capita Income]
averages_df = census_data.groupby([Year, State])[averages_columns].mean().reset_index
totals_df.rename(columns={
Population: Total Population
Employed Civilians: Total Employed Civilians
Unemployed Civilians: Total Unemployed Civilians
People in the Military: Total People in the Military
Poverty Count: Total Poverty Count}
inplace=true)
averages_df.rename(columns={
Median Age': Average Median Age,
Household Income': Average Household Income
Per Capita Income: Average Per Capita Income
} inplace = true)

## Mod
totals_CSV_path = /mnt/data/totals_by_year_and_state.CSV
averages_CSV_path = /mnt/data/averages_by_year_and_state.CSV
totals_df.to_CSV(totals_CSV_path, index=false)
averages_df.to_CSV(averages_CSV_path, index=false)
(totals_CSV_path, averages_CSV_path)

  # Visualization Complete

  # San Francisco Municipal
import pandas as pd
df = pd.read.CSV(/mnt/data/SFO_Airport_Utility_Consumption.CSV)
unique_utilities = df['Utility'].unique()
unique_utilities

## Wrangle
gas_tenant_df = df[(df[Utility] = Gas) & (df[Owner] = Tenant)]
sorted_gas_tenant_df = gas_tenant_df.sort_values(by=Usage, ascending=false)
sorted_gas_tenant_df.reset_index(drop=true, inplace=true)
sorted_gas_tenant_df

## Mod
gas_tenant_df[Date] = pd.to_datetime(gas_tenant_df['Year'].astype(str) + gas_tenant_df['Month Number'].astype(str) + -01)
plt.figure(figsize=(14, 7))
sns.lineplot(x=Date, y=Usage, data=gas_tenant_df, marker=o)
plt.title(Gas Consumption by Tenants Over Time)
plt.xlabel(Date)
plt.ylabel(Gas Consumption (Therms))
plt.grid(true)
plt.xticks(rotation=45)
plt.tight_layout()
plt.savefig(/mnt/data/gas_consumption_by_tenants_over_time_corrected.png)
plt.show()
corrected_plot_path = /mnt/data/gas_consumption_by_tenants_over_time_corrected.png
corrected_plot_path

  # Visualization Complete
